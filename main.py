import streamlit as st
from PIL import Image
from rag_pipeline import load_and_translate_documents, create_vectorstore, retrieve_relevant_chunks
from model_utils import load_model, generate_response
from llava_utils import load_llava_model, analyze_image, load_blip2_model, analyze_with_blip2
from deep_translator import GoogleTranslator


st.set_page_config(page_title="Dijital Pazarlama Chatbot'u", layout="wide")

st.image("FDEEP.AI.png", width=300)
st.title("ğŸ“ˆ Dijital Pazarlama ve Dijital ReklamcÄ±lÄ±k Chatbot'u ğŸ¤– ")
st.markdown("KiÅŸisel dijital pazarlama asistanÄ±nÄ±z ğŸ¤– ")

# Belge klasÃ¶rÃ¼ yolu
PDF_FOLDER = r"C:\Users\feyza\OneDrive\MasaÃ¼stÃ¼\teknofest_chatbot\dijitalpazarlama_reklamkaynaklarÄ±"

# Belgeleri yÃ¼kle ve vektÃ¶r oluÅŸtur
with st.spinner("Belgeler iÅŸleniyor..."):
    documents = load_and_translate_documents(PDF_FOLDER)
    vectorstore = create_vectorstore(documents)

# Model seÃ§imi
model_key = st.selectbox("Kullanmak istediÄŸiniz modeli seÃ§in:", ["mistral", "llama3.1.8", "qwen3", "gemma3", "deepseek-r1"])
model_name = load_model(model_key)

# ğŸ§  Chat ArayÃ¼zÃ¼
st.subheader("ğŸ’¬ Soru-Cevap (Chatbot)")
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []

user_input = st.text_input("Dijital pazarlama ve dijital reklamcÄ±lÄ±k ile ilgili sorunuzu yazÄ±n:")

if st.button("GÃ¶nder"):
    if not user_input.strip():
        st.warning("LÃ¼tfen bir soru yazÄ±n.")
    else:
        relevant_docs = retrieve_relevant_chunks(vectorstore, user_input)
        context = "\n".join(relevant_docs)
        prompt = f"Belgelere dayalÄ± olarak yanÄ±t ver. Cevap TÃ¼rkÃ§e olsun ve sade bir dille yaz:\n\nKullanÄ±cÄ±nÄ±n sorusu: {user_input}\n\nÄ°lgili belgeler:\n{context}"

        with st.spinner("YanÄ±t oluÅŸturuluyor..."):
            answer = generate_response(model_name, prompt)

        st.session_state.chat_history.append(("ğŸ§‘â€ğŸ’» Soru", user_input))
        st.session_state.chat_history.append(("ğŸ¤– YanÄ±t", answer))

# Sohbet geÃ§miÅŸini gÃ¶ster
for role, msg in st.session_state.chat_history:
    st.markdown(f"*{role}:* {msg}")

# ğŸ–¼ï¸ GÃ¶rsel Yorumlama AsistanÄ± (YalnÄ±zca Ãœcretsiz Lokal Modeller)

st.subheader("ğŸ–¼ï¸ GÃ¶rsel Yorumlama AsistanÄ±")

model_selector = st.selectbox(
    "GÃ¶rsel yorumlama iÃ§in model seÃ§in:",
    [
        "llava-hf (lokal)",
        "blip2-hf (lokal)",
        "ocr (gÃ¶rseldeki yazÄ±larÄ± oku)",
        "classification (ne resmi olduÄŸunu tahmin et)"
    ]
)

uploaded_image = st.file_uploader("Bir gÃ¶rsel yÃ¼kleyin", type=["jpg", "jpeg", "png"])
question = st.text_input("GÃ¶rselle ilgili ne Ã¶ÄŸrenmek istiyorsunuz?")

if uploaded_image:
    image = Image.open(uploaded_image).convert("RGB")

    if model_selector == "llava-hf (lokal)" and question:
        with st.spinner("LLaVA v1.6 modeli yÃ¼kleniyor..."):
            processor, llava_model = load_llava_model()
        with st.spinner("GÃ¶rsel analiz ediliyor..."):
            output = analyze_image(processor, llava_model, image, question)
        st.success("LLaVA CevabÄ±:")
        st.write(output)

    elif model_selector == "blip2-hf (lokal)" and question:
        with st.spinner("BLIP-2 modeli yÃ¼kleniyor..."):
            blip_processor, blip_model = load_blip2_model()
        with st.spinner("BLIP-2 analiz ediyor..."):
            output = analyze_with_blip2(blip_processor, blip_model, image, question)
        st.success("BLIP-2 (Ä°ngilizce) TanÄ±m:")
        st.write(output)

        from llava_utils import translate_and_summarize
        st.markdown("**ğŸ’¬ TÃ¼rkÃ§eye Ã‡evrilmiÅŸ Pazarlama Metni:**")
        marketing_text = translate_and_summarize(output, model_name)
        st.write(marketing_text)

    elif model_selector == "ocr (gÃ¶rseldeki yazÄ±larÄ± oku)":
        with st.spinner("Metin algÄ±lanÄ±yor (OCR)..."):
            from ocr_utils import extract_text_from_image
            ocr_text = extract_text_from_image(image)
        st.success("OCR Sonucu:")
        st.code(ocr_text if ocr_text else "Metin bulunamadÄ±.")

    elif model_selector == "classification (ne resmi olduÄŸunu tahmin et)":
        with st.spinner("GÃ¶rsel sÄ±nÄ±flandÄ±rÄ±lÄ±yor..."):
            from image_classification_utils import classify_image
            label = classify_image(image)
        st.success(f"ğŸ–¼ï¸ Tahmini sÄ±nÄ±f:")
        st.write(label)

        # Ã‡Ä±ktÄ±yÄ± gÃ¶ster
    st.image(image, caption="YÃ¼klenen GÃ¶rsel", use_container_width=True)
    if model_selector in ["llava-hf (lokal)", "blip2-hf (lokal)"] and question:
        st.markdown("**YanÄ±t:**")
        st.write(output)

"""
OCR seÃ§ildiyse â†’ Resimdeki metni Ã§Ä±karÄ±r â†’ sana sunar.

SÄ±nÄ±flandÄ±rma seÃ§ildiyse â†’ Resmin ne olduÄŸunu sÃ¶yler. (â€œfincanâ€ gibi)

LLaVA seÃ§ildiyse â†’ â€œFincanâ€ + â€œreklam Ã¶nerisiâ€ gibi sorulara zengin cevap verir.

BLIP-2 seÃ§ildiyse â†’ GÃ¶rselin Ã¶zeti + fikir Ã¼retir, bu da pazarlama iÃ§erikleri iÃ§in kullanÄ±ÅŸlÄ±dÄ±r. """